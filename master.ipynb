{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2113bac",
   "metadata": {},
   "source": [
    "# Differentially Private Synthetic Tabular Data Generation\n",
    "\n",
    "## Using DP-SGD with Variational Autoencoder\n",
    "\n",
    "**Dataset:** Synthetic Telemetry Data (May-July 2024)  \n",
    "**Objective:** Generate differentially private synthetic data while preserving statistical utility  \n",
    "**Method:** DP-SGD applied to VAE training\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027180e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812334e",
   "metadata": {},
   "source": [
    "## 1. Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"data/synthetic_telemetry_data.csv\")\n",
    "print(f\"Shape: {df_raw.shape}, {len(df_raw):,} records\\n\")\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e845b2",
   "metadata": {},
   "source": [
    "## 2. EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aaf3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "product_counts = df_raw[\"Product Type\"].value_counts()\n",
    "axes[0].bar(product_counts.index, product_counts.values, color=\"skyblue\")\n",
    "axes[0].set_title(\"Product Type Distribution\")\n",
    "axes[0].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "event_counts = df_raw[\"Event Type\"].value_counts()\n",
    "axes[1].bar(event_counts.index, event_counts.values, color=\"coral\")\n",
    "axes[1].set_title(\"Event Type Distribution\")\n",
    "axes[1].grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bccdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"Time of Event\"] = pd.to_datetime(df_raw[\"Time of Event\"])\n",
    "df_raw[\"Date\"] = df_raw[\"Time of Event\"].dt.date\n",
    "df_raw[\"Hour\"] = df_raw[\"Time of Event\"].dt.hour\n",
    "df_raw[\"DayOfWeek\"] = df_raw[\"Time of Event\"].dt.day_name()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "daily_counts = df_raw.groupby(\"Date\").size()\n",
    "axes[0].plot(daily_counts.index, daily_counts.values)\n",
    "axes[0].set_title(\"Events per Day\")\n",
    "axes[0].set_xlabel(\"Date\")\n",
    "axes[0].set_ylabel(\"Events\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "hourly_counts = df_raw[\"Hour\"].value_counts().sort_index()\n",
    "axes[1].bar(hourly_counts.index, hourly_counts.values, color=\"green\")\n",
    "axes[1].set_title(\"Events by Hour\")\n",
    "axes[1].set_xlabel(\"Hour\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "\n",
    "day_order = [\n",
    "    \"Monday\",\n",
    "    \"Tuesday\",\n",
    "    \"Wednesday\",\n",
    "    \"Thursday\",\n",
    "    \"Friday\",\n",
    "    \"Saturday\",\n",
    "    \"Sunday\",\n",
    "]\n",
    "dow_counts = df_raw[\"DayOfWeek\"].value_counts().reindex(day_order)\n",
    "axes[2].bar(dow_counts.index, dow_counts.values, color=\"purple\")\n",
    "axes[2].set_title(\"Events by Day of Week\")\n",
    "axes[2].set_xlabel(\"Day\")\n",
    "axes[2].set_ylabel(\"Count\")\n",
    "axes[2].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f584e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab = pd.crosstab(df_raw[\"Product Type\"], df_raw[\"Event Type\"], margins=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(\n",
    "    crosstab.iloc[:-1, :-1],\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"YlOrRd\",\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"label\": \"Count\"},\n",
    ")\n",
    "plt.title(\"Product Type × Event Type Heatmap\")\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.ylabel(\"Product Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c62290",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "We prepare the data for the VAE by:\n",
    "\n",
    "1. Dropping the `User ID` column (not needed for modeling)\n",
    "2. Converting timestamps to Unix seconds for numerical representation\n",
    "3. One-hot encoding categorical variables\n",
    "4. Standardizing numerical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9767e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "df = df.drop(columns=[\"User ID\"], errors=\"ignore\")\n",
    "df[\"TimeSeconds\"] = pd.to_datetime(df[\"Time of Event\"]).astype(\"int64\") // 1_000_000_000\n",
    "df[\"TimeOriginal\"] = df[\"Time of Event\"]\n",
    "\n",
    "categorical_cols = [\"Product Type\", \"Event Type\"]\n",
    "numeric_cols = [\"TimeSeconds\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"),\n",
    "            categorical_cols,\n",
    "        ),\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "X_transformed = transformer.fit_transform(df[categorical_cols + numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X_transformed, test_size=0.2, random_state=42)\n",
    "print(f\"{X_train.shape}, {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d1596",
   "metadata": {},
   "source": [
    "## 4. Dataset and DataLoader Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1717238",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TelemetryDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n",
    "\n",
    "train_dataset = TelemetryDataset(X_train)\n",
    "test_dataset = TelemetryDataset(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8c458",
   "metadata": {},
   "source": [
    "## 5. Model Architecture: Variational Autoencoder (VAE)\n",
    "\n",
    "The VAE consists of:\n",
    "\n",
    "- **Encoder**: Maps input data to latent distribution parameters (μ, log σ²)\n",
    "- **Latent space**: Lower-dimensional representation (default: 8 dimensions)\n",
    "- **Decoder**: Reconstructs data from latent samples\n",
    "\n",
    "For DP-SGD, we apply:\n",
    "\n",
    "- **Gradient clipping**: Bounds per-sample gradient L2 norm\n",
    "- **Gaussian noise**: Added to clipped gradients for privacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f11af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=8, hidden_dims=[64, 32]):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        encoder_layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            encoder_layers.extend(\n",
    "                [nn.Linear(prev_dim, h_dim), nn.ReLU(), nn.BatchNorm1d(h_dim)]\n",
    "            )\n",
    "            prev_dim = h_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        decoder_layers = []\n",
    "        prev_dim = latent_dim\n",
    "        for h_dim in reversed(hidden_dims):\n",
    "            decoder_layers.extend(\n",
    "                [nn.Linear(prev_dim, h_dim), nn.ReLU(), nn.BatchNorm1d(h_dim)]\n",
    "            )\n",
    "            prev_dim = h_dim\n",
    "\n",
    "        decoder_layers.append(nn.Linear(hidden_dims[0], input_dim))\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = X_train.shape[1]\n",
    "model = VAE(input_dim=input_dim, latent_dim=8, hidden_dims=[64, 32]).to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b220471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(recon_x, x, mu, logvar, beta=1.0):\n",
    "    recon_loss = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    total_loss = recon_loss + beta * kl_div\n",
    "    \n",
    "    return total_loss, recon_loss, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6911a1",
   "metadata": {},
   "source": [
    "## 6. Differential Privacy Setup with Opacus\n",
    "\n",
    "**Privacy Parameters:**\n",
    "- **ε (epsilon)**: Privacy budget (lower = stronger privacy)\n",
    "- **δ (delta)**: Probability of privacy breach (typically ≪ 1/n)\n",
    "- **Max grad norm (C)**: Clipping threshold for gradients\n",
    "- **Noise multiplier (σ)**: Scale of Gaussian noise\n",
    "\n",
    "We'll track privacy budget using Opacus's privacy accountant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03171af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_EPSILON = 8.0\n",
    "TARGET_DELTA = 1e-5\n",
    "MAX_GRAD_NORM = 1.0\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModuleValidator.fix(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83635fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    noise_multiplier=1.1,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb242bf",
   "metadata": {},
   "source": [
    "## 7. Training Loop with Privacy Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, device, beta=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    n_batches = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_batch, mu, logvar = model(batch)\n",
    "        loss, recon_loss, kl_loss = vae_loss_function(\n",
    "            recon_batch, batch, mu, logvar, beta\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_recon_loss += recon_loss.item()\n",
    "        total_kl_loss += kl_loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    return (\n",
    "        total_loss / n_batches,\n",
    "        total_recon_loss / n_batches,\n",
    "        total_kl_loss / n_batches,\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, device, beta=1.0):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    n_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            recon_batch, mu, logvar = model(batch)\n",
    "            loss, recon_loss, kl_loss = vae_loss_function(\n",
    "                recon_batch, batch, mu, logvar, beta\n",
    "            )\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            total_kl_loss += kl_loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "    return (\n",
    "        total_loss / n_batches,\n",
    "        total_recon_loss / n_batches,\n",
    "        total_kl_loss / n_batches,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a136943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_recon\": [],\n",
    "    \"train_kl\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"test_recon\": [],\n",
    "    \"test_kl\": [],\n",
    "    \"epsilon\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_recon, train_kl = train_epoch(\n",
    "        model, train_loader, optimizer, device\n",
    "    )\n",
    "    test_loss, test_recon, test_kl = evaluate(model, test_loader, device)\n",
    "\n",
    "    epsilon = privacy_engine.get_epsilon(delta=TARGET_DELTA)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_recon\"].append(train_recon)\n",
    "    history[\"train_kl\"].append(train_kl)\n",
    "    history[\"test_loss\"].append(test_loss)\n",
    "    history[\"test_recon\"].append(test_recon)\n",
    "    history[\"test_kl\"].append(test_kl)\n",
    "    history[\"epsilon\"].append(epsilon)\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(\n",
    "            f\"Epoch {epoch:3d}/{EPOCHS} | \"\n",
    "            f\"Train loss: {train_loss:8.2f} | \"\n",
    "            f\"Test loss: {test_loss:8.2f} | \"\n",
    "            f\"ε: {epsilon:.2f}\"\n",
    "        )\n",
    "\n",
    "print(f\"Final ε: {history['epsilon'][-1]:.4f} (target: {TARGET_EPSILON})\")\n",
    "print(f\"Final δ: {TARGET_DELTA}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
