{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9bf65fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Config(data_path=WindowsPath('../data/telemetry.csv'), output_path=WindowsPath('../data/synthetic.csv'), batch_size=256, latent_dim=16, epochs=20, noise_multiplier=1.2, max_grad_norm=1.0, target_epsilon=2.0, delta=1e-05, synth_samples=10000),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from opacus import PrivacyEngine\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data-path\", type=Path, default=Path(\"../data/telemetry.csv\"))\n",
    "parser.add_argument(\"--output-path\", type=Path, default=Path(\"../data/synthetic.csv\"))\n",
    "parser.add_argument(\"--batch-size\", type=int, default=256)\n",
    "parser.add_argument(\"--latent-dim\", type=int, default=16)\n",
    "parser.add_argument(\"--epochs\", type=int, default=20)\n",
    "parser.add_argument(\"--noise-multiplier\", type=float, default=1.2)\n",
    "parser.add_argument(\"--max-grad-norm\", type=float, default=1.0)\n",
    "parser.add_argument(\"--target-epsilon\", type=float, default=2.0)\n",
    "parser.add_argument(\"--delta\", type=float, default=1e-5)\n",
    "parser.add_argument(\"--synth-samples\", type=int, default=10000)\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_path: Path\n",
    "    output_path: Path\n",
    "    batch_size: int\n",
    "    latent_dim: int\n",
    "    epochs: int\n",
    "    noise_multiplier: float\n",
    "    max_grad_norm: float\n",
    "    target_epsilon: float\n",
    "    delta: float\n",
    "    synth_samples: int\n",
    "\n",
    "cfg = Config(**vars(args))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2903621a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  Product Type Event Type        Time of Event  TimeSeconds\n",
       " 0            C       open  2024-05-14 07:34:33   1715672073\n",
       " 1            E      close  2024-06-17 14:43:26   1718635406\n",
       " 2            C      close  2024-07-13 05:20:43   1720848043\n",
       " 3            D       open  2024-06-11 17:39:05   1718127545\n",
       " 4            C       save  2024-06-23 18:20:35   1719166835,\n",
       " np.int64(1714521637),\n",
       " np.int64(1722383984))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(cfg.data_path)\n",
    "if \"User ID\" in df.columns:\n",
    "    df = df.drop(columns=[\"User ID\"])\n",
    "\n",
    "df[\"TimeSeconds\"] = pd.to_datetime(df[\"Time of Event\"]).astype(\"int64\") // 1_000_000_000\n",
    "categorical_cols = [\"Product Type\", \"Event Type\"]\n",
    "numeric_cols = [\"TimeSeconds\"]\n",
    "time_min, time_max = df[\"TimeSeconds\"].min(), df[\"TimeSeconds\"].max()\n",
    "df.head(), time_min, time_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184f2e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152356, 13), [7, 5], 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\",\n",
    "         sparse_output=False), categorical_cols),\n",
    "        (\"numeric\", StandardScaler(), numeric_cols),\n",
    "    ]\n",
    ")\n",
    "X_real = transformer.fit_transform(df[categorical_cols + numeric_cols])\n",
    "cat_encoder: OneHotEncoder = transformer.named_transformers_[\"categorical\"]\n",
    "cat_sizes = [len(c) for c in cat_encoder.categories_]\n",
    "cat_total = sum(cat_sizes)\n",
    "num_scaler: StandardScaler = transformer.named_transformers_[\"numeric\"]\n",
    "\n",
    "X_real.shape, cat_sizes, cat_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aeb8470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152356, 0.0016802751450550027)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TelemetryDataset(Dataset):\n",
    "    def __init__(self, matrix: np.ndarray):\n",
    "        self.tensor = torch.tensor(matrix, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.tensor.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        return self.tensor[idx]\n",
    "\n",
    "dataset = TelemetryDataset(X_real)\n",
    "dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True, drop_last=True)\n",
    "sample_rate = cfg.batch_size / len(dataset)\n",
    "\n",
    "len(dataset), sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c0d44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Autoencoder(\n",
       "   (encoder): Sequential(\n",
       "     (0): Linear(in_features=13, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=128, out_features=16, bias=True)\n",
       "   )\n",
       "   (decoder): Sequential(\n",
       "     (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=128, out_features=13, bias=True)\n",
       "     (3): Sigmoid()\n",
       "   )\n",
       " ),\n",
       " 7709)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, latent_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "model = Autoencoder(X_real.shape[1], cfg.latent_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model, sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1881163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\AppData\\Local\\Temp\\ipykernel_22132\\599489257.py:20: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
      "  loss.backward()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss=0.1094 | ε=0.153\n",
      "Epoch 02 | loss=0.0711 | ε=0.212\n",
      "Epoch 03 | loss=0.0594 | ε=0.259\n",
      "Epoch 04 | loss=0.0511 | ε=0.299\n",
      "Epoch 05 | loss=0.0485 | ε=0.335\n",
      "Epoch 06 | loss=0.0459 | ε=0.367\n",
      "Epoch 07 | loss=0.0445 | ε=0.397\n",
      "Epoch 08 | loss=0.0436 | ε=0.425\n",
      "Epoch 09 | loss=0.0436 | ε=0.452\n",
      "Epoch 10 | loss=0.0438 | ε=0.477\n",
      "Epoch 11 | loss=0.0430 | ε=0.501\n",
      "Epoch 12 | loss=0.0434 | ε=0.525\n",
      "Epoch 13 | loss=0.0434 | ε=0.547\n",
      "Epoch 14 | loss=0.0428 | ε=0.569\n",
      "Epoch 15 | loss=0.0427 | ε=0.590\n",
      "Epoch 16 | loss=0.0428 | ε=0.610\n",
      "Epoch 17 | loss=0.0431 | ε=0.630\n",
      "Epoch 18 | loss=0.0427 | ε=0.649\n",
      "Epoch 19 | loss=0.0424 | ε=0.667\n",
      "Epoch 20 | loss=0.0426 | ε=0.686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float64(0.15265187735663266),\n",
       " np.float64(0.21217591080216056),\n",
       " np.float64(0.2589209657430531),\n",
       " np.float64(0.2989154896853333),\n",
       " np.float64(0.33454099001913706),\n",
       " np.float64(0.36703421953641385),\n",
       " np.float64(0.39713686640341445),\n",
       " np.float64(0.4253356043686182),\n",
       " np.float64(0.4519706285661513),\n",
       " np.float64(0.47729082950604185),\n",
       " np.float64(0.5014849720728536),\n",
       " np.float64(0.5247002452613325),\n",
       " np.float64(0.5470541468930556),\n",
       " np.float64(0.5686422243069562),\n",
       " np.float64(0.5895434585435535),\n",
       " np.float64(0.609824003712563),\n",
       " np.float64(0.6295399921745031),\n",
       " np.float64(0.6487395116032678),\n",
       " np.float64(0.6674641264862889),\n",
       " np.float64(0.6857500656724668)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privacy_engine = PrivacyEngine()\n",
    "model, optimizer, dataloader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=dataloader,\n",
    "    noise_multiplier=cfg.noise_multiplier,\n",
    "    max_grad_norm=cfg.max_grad_norm,\n",
    ")\n",
    "\n",
    "eps_history = []\n",
    "\n",
    "for epoch in range(1, cfg.epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(batch)\n",
    "        loss = criterion(recon, batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * batch.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    try:\n",
    "        epsilon = privacy_engine.accountant.get_epsilon(delta=cfg.delta)\n",
    "    except ValueError:\n",
    "        epsilon = float(\"nan\")\n",
    "\n",
    "    eps_history.append(epsilon)\n",
    "    print(f\"Epoch {epoch:02d} | loss={epoch_loss:.4f} | ε={epsilon:.3f}\")\n",
    "    if np.isfinite(cfg.target_epsilon) and np.isfinite(epsilon) and epsilon >= cfg.target_epsilon:\n",
    "        print(f\"Stopping early: ε target {cfg.target_epsilon} reached.\")\n",
    "        break\n",
    "\n",
    "eps_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "043b6c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 13),\n",
       " array([[0.42610097, 0.014578  , 0.9352448 , 0.34951293, 0.34734988,\n",
       "         0.3107458 , 0.06762154, 0.14543477, 0.17739493, 0.10765409,\n",
       "         0.81321365, 0.5616892 , 0.2926853 ],\n",
       "        [0.7889601 , 0.12428693, 0.11767975, 0.36946914, 0.25241432,\n",
       "         0.6883236 , 0.02759617, 0.24528891, 0.3882285 , 0.6869072 ,\n",
       "         0.36680713, 0.04049201, 0.01743271]], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    latent = torch.randn(cfg.synth_samples, cfg.latent_dim, device=device)\n",
    "    synth_matrix = model.decoder(latent).cpu().numpy()\n",
    "\n",
    "synth_matrix.shape, synth_matrix[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e4e9768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data saved to ..\\data\\synthetic.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Event Type</th>\n",
       "      <th>TimeSeconds</th>\n",
       "      <th>Time of Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>reset</td>\n",
       "      <td>1.719125e+09</td>\n",
       "      <td>2024-06-23 06:47:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>open</td>\n",
       "      <td>1.718502e+09</td>\n",
       "      <td>2024-06-16 01:33:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>close</td>\n",
       "      <td>1.720718e+09</td>\n",
       "      <td>2024-07-11 17:08:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>save</td>\n",
       "      <td>1.718951e+09</td>\n",
       "      <td>2024-06-21 06:21:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Others</td>\n",
       "      <td>open</td>\n",
       "      <td>1.720519e+09</td>\n",
       "      <td>2024-07-09 09:55:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product Type Event Type   TimeSeconds       Time of Event\n",
       "0            C      reset  1.719125e+09 2024-06-23 06:47:28\n",
       "1            A       open  1.718502e+09 2024-06-16 01:33:52\n",
       "2            C      close  1.720718e+09 2024-07-11 17:08:16\n",
       "3            A       save  1.718951e+09 2024-06-21 06:21:52\n",
       "4       Others       open  1.720519e+09 2024-07-09 09:55:12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_cats = []\n",
    "start = 0\n",
    "for col_name, size, labels in zip(categorical_cols, cat_sizes, cat_encoder.categories_):\n",
    "    block = synth_matrix[:, start:start + size]\n",
    "    values = labels[block.argmax(axis=1)]\n",
    "    decoded_cats.append(pd.Series(values, name=col_name))\n",
    "    start += size\n",
    "\n",
    "cat_df = pd.concat(decoded_cats, axis=1)\n",
    "num_block = synth_matrix[:, cat_total:]\n",
    "num_vals = num_scaler.inverse_transform(num_block)\n",
    "num_df = pd.DataFrame(num_vals, columns=numeric_cols)\n",
    "num_df[\"TimeSeconds\"] = num_df[\"TimeSeconds\"].clip(time_min, time_max)\n",
    "num_df[\"Time of Event\"] = pd.to_datetime(num_df[\"TimeSeconds\"], unit=\"s\")\n",
    "\n",
    "synthetic_df = pd.concat([cat_df.reset_index(drop=True), num_df.reset_index(drop=True)], axis=1)\n",
    "synthetic_df.to_csv(cfg.output_path, index=False)\n",
    "print(f\"Synthetic data saved to {cfg.output_path}\")\n",
    "\n",
    "synthetic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d67c95d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TimeSeconds summary ===\n",
      "  mean: real=1718462125.60 | synth=1719405440.00\n",
      "median: real=1718467899.50 | synth=1719257856.00\n",
      "   std: real=2265577.72 | synth=753663.06\n",
      "   min: real=1714521637.00 | synth=1718462208.00\n",
      "   max: real=1722383984.00 | synth=1720727296.00\n",
      "\n",
      "=== Category distributions ===\n",
      "\n",
      "Product Type\n",
      "                  real  synthetic\n",
      "Product Type                     \n",
      "A             0.151592     0.1613\n",
      "B             0.251549     0.0931\n",
      "C             0.186865     0.1196\n",
      "D             0.200393     0.2906\n",
      "E             0.010377     0.0153\n",
      "F             0.098874     0.2248\n",
      "Others        0.100350     0.0953\n",
      "\n",
      "Event Type\n",
      "                real  synthetic\n",
      "Event Type                     \n",
      "close       0.307733     0.1355\n",
      "error       0.032326     0.1534\n",
      "open        0.382696     0.2450\n",
      "reset       0.067454     0.2686\n",
      "save        0.209792     0.1975\n"
     ]
    }
   ],
   "source": [
    "def summarize_time(real: pd.Series, synth: pd.Series) -> None:\n",
    "    stats = {\n",
    "        \"mean\": (real.mean(), synth.mean()),\n",
    "        \"median\": (real.median(), synth.median()),\n",
    "        \"std\": (real.std(), synth.std()),\n",
    "        \"min\": (real.min(), synth.min()),\n",
    "        \"max\": (real.max(), synth.max()),\n",
    "    }\n",
    "    for k, (r, s) in stats.items():\n",
    "        print(f\"{k:>6}: real={r:.2f} | synth={s:.2f}\")\n",
    "\n",
    "\n",
    "print(\"=== TimeSeconds summary ===\")\n",
    "summarize_time(df[\"TimeSeconds\"], synthetic_df[\"TimeSeconds\"])\n",
    "print(\"\\n=== Category distributions ===\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}\")\n",
    "    print(pd.DataFrame({\n",
    "        \"real\": df[col].value_counts(normalize=True),\n",
    "        \"synthetic\": synthetic_df[col].value_counts(normalize=True),\n",
    "    }))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
