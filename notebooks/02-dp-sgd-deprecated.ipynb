{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e792c173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Config(data_path=WindowsPath('../data/telemetry.csv'), output_path=WindowsPath('../data/synthetic.csv'), batch_size=256, latent_dim=16, epochs=20, noise_multiplier=1.2, max_grad_norm=1.0, target_epsilon=2.0, delta=1e-05, synth_samples=10000, latent_jitter=0.1),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from opacus import PrivacyEngine\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data-path\", type=Path, default=Path(\"../data/telemetry.csv\"))\n",
    "parser.add_argument(\"--output-path\", type=Path, default=Path(\"../data/synthetic.csv\"))\n",
    "parser.add_argument(\"--batch-size\", type=int, default=256)\n",
    "parser.add_argument(\"--latent-dim\", type=int, default=16)\n",
    "parser.add_argument(\"--epochs\", type=int, default=20)\n",
    "parser.add_argument(\"--noise-multiplier\", type=float, default=1.2)\n",
    "parser.add_argument(\"--max-grad-norm\", type=float, default=1.0)\n",
    "parser.add_argument(\"--target-epsilon\", type=float, default=2.0)\n",
    "parser.add_argument(\"--delta\", type=float, default=1e-5)\n",
    "parser.add_argument(\"--synth-samples\", type=int, default=10000)\n",
    "parser.add_argument(\"--latent-jitter\", type=float, default=0.1)\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_path: Path\n",
    "    output_path: Path\n",
    "    batch_size: int\n",
    "    latent_dim: int\n",
    "    epochs: int\n",
    "    noise_multiplier: float\n",
    "    max_grad_norm: float\n",
    "    target_epsilon: float\n",
    "    delta: float\n",
    "    synth_samples: int\n",
    "    latent_jitter: float\n",
    "\n",
    "\n",
    "cfg = Config(**vars(args))\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4611c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  Product Type Event Type        Time of Event  TimeSeconds\n",
       " 0            C       open  2024-05-14 07:34:33   1715672073\n",
       " 1            E      close  2024-06-17 14:43:26   1718635406\n",
       " 2            C      close  2024-07-13 05:20:43   1720848043\n",
       " 3            D       open  2024-06-11 17:39:05   1718127545\n",
       " 4            C       save  2024-06-23 18:20:35   1719166835,\n",
       " np.int64(1714521637),\n",
       " np.int64(1722383984))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(cfg.data_path)\n",
    "if \"User ID\" in df.columns:\n",
    "    df = df.drop(columns=[\"User ID\"])\n",
    "\n",
    "df[\"TimeSeconds\"] = pd.to_datetime(df[\"Time of Event\"]).astype(\"int64\") // 1_000_000_000\n",
    "\n",
    "categorical_cols = [\"Product Type\", \"Event Type\"]\n",
    "numeric_cols = [\"TimeSeconds\"]\n",
    "\n",
    "time_min, time_max = df[\"TimeSeconds\"].min(), df[\"TimeSeconds\"].max()\n",
    "df.head(), time_min, time_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d66c443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152356, 13), [7, 5], 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"categorical\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "            categorical_cols,\n",
    "        ),\n",
    "        (\"numeric\", StandardScaler(), numeric_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_real = transformer.fit_transform(df[categorical_cols + numeric_cols])\n",
    "cat_encoder: OneHotEncoder = transformer.named_transformers_[\"categorical\"]\n",
    "cat_sizes: List[int] = [len(c) for c in cat_encoder.categories_]\n",
    "cat_total = sum(cat_sizes)\n",
    "num_scaler: StandardScaler = transformer.named_transformers_[\"numeric\"]\n",
    "\n",
    "X_real.shape, cat_sizes, cat_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3c9ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152356, 0.0016802751450550027)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_targets_list = []\n",
    "start = 0\n",
    "for size in cat_sizes:\n",
    "    block = X_real[:, start:start + size]\n",
    "    cat_targets_list.append(block.argmax(axis=1))\n",
    "    start += size\n",
    "\n",
    "cat_targets = np.stack(cat_targets_list, axis=1).astype(np.int64)\n",
    "numeric_targets = X_real[:, cat_total:].astype(np.float32)\n",
    "\n",
    "features = torch.tensor(X_real, dtype=torch.float32)\n",
    "cat_targets_tensor = torch.tensor(cat_targets, dtype=torch.long)\n",
    "num_targets_tensor = torch.tensor(numeric_targets, dtype=torch.float32)\n",
    "\n",
    "class TelemetryDataset(Dataset):\n",
    "    def __init__(self, features: torch.Tensor, cat_targets: torch.Tensor, num_targets: torch.Tensor):\n",
    "        self.features = features\n",
    "        self.cat_targets = cat_targets\n",
    "        self.num_targets = num_targets\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.features.size(0)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return (\n",
    "            self.features[idx],\n",
    "            self.cat_targets[idx],\n",
    "            self.num_targets[idx],\n",
    "        )\n",
    "\n",
    "dataset = TelemetryDataset(features, cat_targets_tensor, num_targets_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "len(dataset), cfg.batch_size / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76542468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TelemetryAutoencoder(\n",
       "   (encoder): Sequential(\n",
       "     (0): Linear(in_features=13, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=128, out_features=16, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (cat_decoders): ModuleList(\n",
       "     (0): Linear(in_features=16, out_features=7, bias=True)\n",
       "     (1): Linear(in_features=16, out_features=5, bias=True)\n",
       "   )\n",
       "   (num_decoder): Linear(in_features=16, out_features=1, bias=True)\n",
       " ),\n",
       " 4077)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TelemetryAutoencoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim: int, latent_dim: int, cat_sizes: List[int], num_dim: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.cat_decoders = nn.ModuleList(\n",
    "            [nn.Linear(latent_dim, size) for size in cat_sizes]\n",
    "        )\n",
    "        self.num_decoder = nn.Linear(latent_dim, num_dim)\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode_from_latent(self, z: torch.Tensor):\n",
    "        cat_logits = [decoder(z) for decoder in self.cat_decoders]\n",
    "        num_out = self.num_decoder(z)\n",
    "        return cat_logits, num_out\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        z = self.encode(x)\n",
    "        cat_logits, num_out = self.decode_from_latent(z)\n",
    "        return cat_logits, num_out, z\n",
    "\n",
    "\n",
    "model = TelemetryAutoencoder(\n",
    "    input_dim=features.shape[1],\n",
    "    latent_dim=cfg.latent_dim,\n",
    "    cat_sizes=cat_sizes,\n",
    "    num_dim=len(numeric_cols),\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "cat_criterion = nn.CrossEntropyLoss()\n",
    "num_criterion = nn.MSELoss()\n",
    "\n",
    "model, sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec721c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jason\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opacus\\privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "11/20/2025 16:11:58:WARNING:Ignoring drop_last as it is not compatible with DPDataLoader.\n",
      "C:\\Users\\jason\\AppData\\Local\\Temp\\ipykernel_11228\\2213409490.py:31: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
      "  loss.backward()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss=1.4746 | ε=0.153\n",
      "Epoch 02 | loss=0.1129 | ε=0.212\n",
      "Epoch 03 | loss=0.0345 | ε=0.259\n",
      "Epoch 04 | loss=0.0166 | ε=0.299\n",
      "Epoch 05 | loss=0.0094 | ε=0.335\n",
      "Epoch 06 | loss=0.0069 | ε=0.367\n",
      "Epoch 07 | loss=0.0048 | ε=0.397\n",
      "Epoch 08 | loss=0.0039 | ε=0.425\n",
      "Epoch 09 | loss=0.0036 | ε=0.452\n",
      "Epoch 10 | loss=0.0032 | ε=0.477\n",
      "Epoch 11 | loss=0.0029 | ε=0.501\n",
      "Epoch 12 | loss=0.0025 | ε=0.525\n",
      "Epoch 13 | loss=0.0022 | ε=0.547\n",
      "Epoch 14 | loss=0.0022 | ε=0.569\n",
      "Epoch 15 | loss=0.0024 | ε=0.590\n",
      "Epoch 16 | loss=0.0017 | ε=0.610\n",
      "Epoch 17 | loss=0.0017 | ε=0.630\n",
      "Epoch 18 | loss=0.0019 | ε=0.649\n",
      "Epoch 19 | loss=0.0018 | ε=0.667\n",
      "Epoch 20 | loss=0.0017 | ε=0.686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float64(0.15265187735659205),\n",
       " np.float64(0.2121759108021326),\n",
       " np.float64(0.25892096574296464),\n",
       " np.float64(0.298915489685312),\n",
       " np.float64(0.33454099001918874),\n",
       " np.float64(0.3670342195364031),\n",
       " np.float64(0.3971368664034298),\n",
       " np.float64(0.4253356043685584),\n",
       " np.float64(0.4519706285660922),\n",
       " np.float64(0.47729082950611196),\n",
       " np.float64(0.5014849720727611),\n",
       " np.float64(0.5247002452613473),\n",
       " np.float64(0.5470541468930574),\n",
       " np.float64(0.5686422243069001),\n",
       " np.float64(0.5895434585435075),\n",
       " np.float64(0.6098240037126326),\n",
       " np.float64(0.6295399921744355),\n",
       " np.float64(0.6487395116032068),\n",
       " np.float64(0.6674641264861636),\n",
       " np.float64(0.6857500656724325)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privacy_engine = PrivacyEngine()\n",
    "model, optimizer, dataloader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=dataloader,\n",
    "    noise_multiplier=cfg.noise_multiplier,\n",
    "    max_grad_norm=cfg.max_grad_norm,\n",
    ")\n",
    "\n",
    "eps_history = []\n",
    "\n",
    "for epoch in range(1, cfg.epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_x, batch_cat_targets, batch_num_targets in dataloader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_cat_targets = batch_cat_targets.to(device)\n",
    "        batch_num_targets = batch_num_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cat_logits, num_pred, _ = model(batch_x)\n",
    "\n",
    "        ce_loss = sum(\n",
    "            cat_criterion(logits, batch_cat_targets[:, idx])\n",
    "            for idx, logits in enumerate(cat_logits)\n",
    "        )\n",
    "        mse_loss = num_criterion(num_pred, batch_num_targets)\n",
    "\n",
    "        loss = ce_loss + mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    try:\n",
    "        epsilon = privacy_engine.accountant.get_epsilon(delta=cfg.delta)\n",
    "    except ValueError:\n",
    "        epsilon = float(\"nan\")\n",
    "\n",
    "    eps_history.append(epsilon)\n",
    "    print(f\"Epoch {epoch:02d} | loss={epoch_loss:.4f} | ε={epsilon:.3f}\")\n",
    "\n",
    "    if (\n",
    "        np.isfinite(cfg.target_epsilon)\n",
    "        and np.isfinite(epsilon)\n",
    "        and epsilon >= cfg.target_epsilon\n",
    "    ):\n",
    "        print(f\"Stopping early: ε target {cfg.target_epsilon} reached.\")\n",
    "        break\n",
    "\n",
    "eps_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0595615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = model._module if hasattr(model, \"_module\") else model\n",
    "inference_model.eval()\n",
    "latent_bank = []\n",
    "\n",
    "latent_loader = DataLoader(dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, _, _ in latent_loader:\n",
    "        z = inference_model.encode(batch_x.to(device))\n",
    "        latent_bank.append(z.cpu())\n",
    "\n",
    "latent_bank = torch.cat(latent_bank, dim=0)\n",
    "\n",
    "indices = np.random.choice(latent_bank.shape[0], size=cfg.synth_samples, replace=True)\n",
    "base_latent = latent_bank[indices]\n",
    "jitter = torch.randn_like(base_latent) * cfg.latent_jitter\n",
    "synth_latent = base_latent + jitter\n",
    "\n",
    "with torch.no_grad():\n",
    "    cat_logits, num_pred = inference_model.decode_from_latent(synth_latent.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "755aaecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data saved to C:\\Users\\jason\\Desktop\\code\\dsc-180a-q1\\data\\synthetic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\AppData\\Local\\Temp\\ipykernel_11228\\2326371296.py:13: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  num_df[\"TimeSeconds\"] = num_df[\"TimeSeconds\"].clip(time_min, time_max).astype(np.int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Event Type</th>\n",
       "      <th>TimeSeconds</th>\n",
       "      <th>Time of Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>save</td>\n",
       "      <td>1715474176</td>\n",
       "      <td>2024-05-12 00:36:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>open</td>\n",
       "      <td>1721368448</td>\n",
       "      <td>2024-07-19 05:54:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>close</td>\n",
       "      <td>1716754176</td>\n",
       "      <td>2024-05-26 20:09:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Others</td>\n",
       "      <td>close</td>\n",
       "      <td>1716259456</td>\n",
       "      <td>2024-05-21 02:44:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>close</td>\n",
       "      <td>1720302208</td>\n",
       "      <td>2024-07-06 21:43:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product Type Event Type  TimeSeconds       Time of Event\n",
       "0            B       save   1715474176 2024-05-12 00:36:16\n",
       "1            D       open   1721368448 2024-07-19 05:54:08\n",
       "2            C      close   1716754176 2024-05-26 20:09:36\n",
       "3       Others      close   1716259456 2024-05-21 02:44:16\n",
       "4            B      close   1720302208 2024-07-06 21:43:28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_categories = []\n",
    "for col_name, logits, labels in zip(\n",
    "    categorical_cols, cat_logits, cat_encoder.categories_\n",
    "):\n",
    "    indices = logits.argmax(dim=1).numpy()\n",
    "    decoded_categories.append(pd.Series(labels[indices], name=col_name))\n",
    "\n",
    "cat_df = pd.concat(decoded_categories, axis=1)\n",
    "\n",
    "num_array = num_pred.numpy()\n",
    "num_vals = num_scaler.inverse_transform(num_array)\n",
    "num_df = pd.DataFrame(num_vals, columns=numeric_cols)\n",
    "num_df[\"TimeSeconds\"] = num_df[\"TimeSeconds\"].clip(time_min, time_max).astype(np.int64)\n",
    "num_df[\"Time of Event\"] = pd.to_datetime(num_df[\"TimeSeconds\"], unit=\"s\")\n",
    "\n",
    "synthetic_df = pd.concat(\n",
    "    [cat_df.reset_index(drop=True), num_df.reset_index(drop=True)], axis=1\n",
    ")\n",
    "synthetic_df = synthetic_df[categorical_cols + numeric_cols + [\"Time of Event\"]]\n",
    "synthetic_df.to_csv(cfg.output_path, index=False)\n",
    "\n",
    "print(f\"Synthetic data saved to {cfg.output_path.resolve()}\")\n",
    "synthetic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d7e0464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ε (δ=1e-05): 0.686\n",
      "\n",
      "=== TimeSeconds summary ===\n",
      "  mean: real=1718462125.60 | synth=1718431902.19\n",
      "median: real=1718467899.50 | synth=1718434240.00\n",
      "   std: real=2265577.72 | synth=2297103.45\n",
      "   min: real=1714521637.00 | synth=1714521637.00\n",
      "   max: real=1722383984.00 | synth=1722383984.00\n",
      "\n",
      "=== Category distributions ===\n",
      "\n",
      "Product Type\n",
      "                  real  synthetic\n",
      "Product Type                     \n",
      "A             0.151592     0.1544\n",
      "B             0.251549     0.2481\n",
      "C             0.186865     0.1877\n",
      "D             0.200393     0.2059\n",
      "E             0.010377     0.0099\n",
      "F             0.098874     0.1007\n",
      "Others        0.100350     0.0933\n",
      "\n",
      "Event Type\n",
      "                real  synthetic\n",
      "Event Type                     \n",
      "open        0.382696     0.3827\n",
      "close       0.307733     0.3066\n",
      "save        0.209792     0.2112\n",
      "reset       0.067454     0.0680\n",
      "error       0.032326     0.0315\n"
     ]
    }
   ],
   "source": [
    "final_epsilon = eps_history[-1] if eps_history else float(\"nan\")\n",
    "print(f\"Final ε (δ={cfg.delta}): {final_epsilon:.3f}\")\n",
    "\n",
    "def summarize_time(real: pd.Series, synth: pd.Series) -> None:\n",
    "    stats = {\n",
    "        \"mean\": (real.mean(), synth.mean()),\n",
    "        \"median\": (real.median(), synth.median()),\n",
    "        \"std\": (real.std(), synth.std()),\n",
    "        \"min\": (real.min(), synth.min()),\n",
    "        \"max\": (real.max(), synth.max()),\n",
    "    }\n",
    "    for k, (r, s) in stats.items():\n",
    "        print(f\"{k:>6}: real={r:.2f} | synth={s:.2f}\")\n",
    "\n",
    "print(\"\\n=== TimeSeconds summary ===\")\n",
    "summarize_time(df[\"TimeSeconds\"], synthetic_df[\"TimeSeconds\"])\n",
    "\n",
    "print(\"\\n=== Category distributions ===\")\n",
    "for col in categorical_cols:\n",
    "    counts = pd.DataFrame({\n",
    "        \"real\": df[col].value_counts(normalize=True),\n",
    "        \"synthetic\": synthetic_df[col].value_counts(normalize=True),\n",
    "    })\n",
    "    print(f\"\\n{col}\")\n",
    "    print(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
