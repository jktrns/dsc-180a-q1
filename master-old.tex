% !TEX TS-program = xelatex
% !BIB TS-program = bibtex
\documentclass[12pt,letterpaper]{article}
\usepackage{style/dsc180reportstyle}

\title{A comparative study of DP-SGD and Private Evolution for differentially private synthetic data}

\author{Mehak Kapur \\
  {\tt mekapur@ucsd.edu} \\\And
  Hana Tjendrawasi  \\
  {\tt htjendrawasi@ucsd.edu} \\\And
  Jason Tran \\
  {\tt jat037@ucsd.edu} \\\And
  Phuc Tran \\
  {\tt pct001@ucsd.edu} \\\And
  Yu-Xiang Wang \\
  {\tt yuxiangw@ucsd.edu} \\}

\begin{document}
\maketitle

\begin{abstract}
    Synthetic data generation with differential privacy enables sharing realistic datasets without exposing any given individual's participation. Two main methodologies dominate current research: (1) differentially private stochastic gradient descent (DP-SGD), which adds noise during model fine-tuning, and (2) Private Evolution (PE), which achieves privacy through inference-only access to foundation model APIs like Stable Diffusion. We implement and compare both methods on benchmark datasets to assess their privacy-utility trade-offs and computational requirements. Our key objective is to evaluate whether this training-free, API-based approach can match DP-SGD's fidelity while offering simpler deployment and lower costs.
\end{abstract}

\begin{center}
Code: \url{https://github.com/jktrns/dsc-180a-q1}
\end{center}

\maketoc
\clearpage

\section{Introduction}

\subsection{Motivation, problem statement}

Contemporary machine learning requires large, labeled datasets that often contain sensitive personal information. Public release of such data threatens individual privacy, necessitating the existence of ``synthetic data'' that maintains statistical utility under formal privacy guarantees. Differential privacy (DP) provides a rigorous mathematical framework ensuring that any individual's inclusion or exclusion from a dataset minimally affects the algorithm's output distribution. DP is quantified by a privacy budget $\varepsilon$ (epsilon), where smaller values provide stronger privacy guarantees but typically reduce data utility.

Traditional DP synthetic data generation employs differentially private stochastic gradient descent (DP-SGD), which adds calibrated noise to per-sample gradients during training. Although effective, DP-SGD requires full access to model weights, substantial computation, and careful privacy parameter tuning. The Private Evolution (PE) framework \citep{lin2025differentiallyprivatesyntheticdata} solves this by generating DP synthetic data through black-box API calls to pre-trained foundation models. We investigate both DP-SGD and PE, comparing their practical trade-offs in fidelity, computational efficiency, and privacy guarantees.

\subsection{Literature review, prior work}

DP, introduced by \cite{dwork2014algorithmic}, provides a rigorous mathematical framework for quantifying privacy guarantees. This foundational work established key mechanisms including Laplace and Gaussian noise addition, along with the composition theorem demonstrating that privacy loss accumulates across multiple queries. This theory is the foundation of all modern DP algorithms.

\cite{abadi2016deep} extended DP to deep learning through DP-SGD, enabling neural network training under formal privacy constraints via per-sample gradient clipping and calibrated Gaussian noise injection. Building on this, \cite{ghalebikesabi2023differentially} demonstrated that fine-tuning diffusion models with DP-SGD generates high-quality synthetic images, though their DP-Diffusion method requires substantial privacy budgets (e.g., $\varepsilon\!\approx\!32$ on CIFAR-10) and significant computational resources.

\cite{lin2025differentiallyprivatesyntheticdata} introduced an alternative paradigm with DP Synthetic Data via Foundation Model APIs (DPSDA). Their PE algorithm achieves DP through black-box API access to pre-trained foundation models, iteratively selecting and mutating samples via a DP nearest-neighbor histogram over private data embeddings. PE achieved Fréchet Inception Distance (FID) of $\leq7.9$ with $\varepsilon=0.67$ on image generation, substantially outperforming DP-Diffusion in both privacy and utility. FID measures the statistical similarity between real and synthetic image distributions, with lower scores indicating higher generation quality. The versatility of this approach has resulted in its extension to text \citep{xie2024differentiallyprivatesyntheticdata} and tabular data \citep{swanberg2025apiaccessllmsuseful}.

\newpage

Despite these advances, comprehensive empirical comparisons between training-based (DP-SGD) and training-free (PE) approaches under controlled conditions remain absent. We address this gap by implementing and evaluating both methods on shared benchmarks, enabling direct assessment of their performance, computational requirements, and privacy-utility trade-offs.

\subsection{Data and experimental setup}

We evaluate our methods on a synthetic telemetry dataset simulating privacy-sensitive system logs. Although artificially generated, we treat this dataset as private data requiring formal privacy guarantees, reflecting realistic deployment scenarios where individual-level records must be protected.

The dataset consists of $n = 10{,}000$ telemetry event records spanning a three-month observation window (May 1–July 31, 2024). Each record $r \in \mathcal{X}$ represents a discrete system event characterized by four attributes: product identifier (categorical, $|\text{domain}| = 7$), event type (categorical, $|\text{domain}| = 5$), timestamp (continuous), and anonymized user identifier. The dataset exhibits temporal structure and categorical correlations typical of operational telemetry systems.

We conduct two classes of experiments on this dataset:

\textbf{Differentially private statistical queries.} We compute summary statistics $f \colon \mathbb{N}^{|\mathcal{X}|} \rightarrow \mathbb{R}^k$ (e.g., frequency histograms, temporal means, product-event correlations) using the Laplace mechanism. For each query $f$ with $\ell_1$-sensitivity $\Delta f$, we release $\mathcal{M}_L(x, f(\cdot), \varepsilon) = f(x) + \text{Lap}(\Delta f / \varepsilon)^k$, calibrating noise to achieve $(\varepsilon, 0)$-differential privacy under varying privacy budgets.

\textbf{Differentially private synthetic data generation.} We implement DP-SGD \citep{abadi2016deep} to train a generative model $G_\theta$ that produces synthetic records $\tilde{x} \sim G_\theta(z)$ satisfying $(\varepsilon, \delta)$-DP. Our architecture uses an autoencoder with latent dimension $d = 16$, trained on preprocessed feature vectors $x \in \mathbb{R}^{d'}$ obtained via one-hot encoding (categorical features) and standardization (temporal features). Privacy is enforced through per-sample gradient clipping (max norm $C = 1.0$) and Gaussian noise injection (multiplier $\sigma = 1.5$) during stochastic optimization. We track cumulative privacy loss via moments accountant \citep{abadi2016deep}, targeting $\varepsilon \leq 5$ at $\delta = 10^{-5}$ after 10 training epochs with batch size 256.

Synthetic data utility is evaluated through distributional similarity metrics: we compare marginal distributions via $\chi^2$ tests (categorical features), Kolmogorov-Smirnov statistics (temporal features), and pairwise correlations. Privacy is empirically validated by computing nearest-neighbor distances between synthetic and real records in transformed feature space, ensuring no synthetic record closely replicates any real individual.

\begin{table}[h!]
\centering
\begin{tabular}{l p{9cm}}
\toprule
\textbf{Feature} & \textbf{Specification} \\
\midrule
Product Type & Categorical variable $\in \{\text{A}, \text{B}, \text{C}, \text{D}, \text{E}, \text{F}, \text{Other}\}$; one-hot encoded to 7-dimensional binary vector \\ 
Event Type & Categorical variable $\in \{\text{open}, \text{close}, \text{save}, \text{reset}, \text{error}\}$; one-hot encoded to 5-dimensional binary vector \\
Timestamp & Continuous temporal feature $\in [t_{\min}, t_{\max}]$ corresponding to event occurrence time (Unix epoch seconds); standardized to zero mean, unit variance \\
User ID & Categorical identifier (cardinality $|\text{users}| \approx 1000$); dropped prior to DP model training to prevent direct identification \\
\bottomrule
\end{tabular}
\caption{Dataset schema and preprocessing. Feature transformations ensure compatibility with gradient-based optimization while preserving semantic structure.}
\label{tab:data_schema}
\end{table}

% \subsection{Data, experimental setup}
% Our project uses a synthetic telemetry dataset provided by the instructor. Although the data are artificially generated, we treat them as sensitive to simulate realistic privacy-critical conditions under which differential privacy methods must operate. The dataset is intended to mimic the structure of real-world system telemetry logs, where each record corresponds to a device, session, or event measurement. \\

% The dataset is provided specifically for two purposes:
% \begin{itemize}
%     \item \textbf{Differentially private data analysis} \\
%     We will compute statistical summaries such as means, histograms, frequency counts, or regression results using DP mechanisms. These tasks simulate real-world applied DP scenarios faced by organizations analyzing sensitive operational data. \\
    
%     \item \textbf{Differentially private synthetic data generation} \\
%     We will release a new synthetic dataset that satisfies differential privacy. The goal is to demonstrate how DP-SGD can be used to train a model that captures useful structure from sensitive data while formally protecting all individuals represented in the original dataset.
% \end{itemize} 

% All evaluations, models, and analyses focus exclusively on the provided sensitive-like dataset to align with the project goal of designing an end-to-end DP workflow. \\

% \textbf{Features} \\
% The telemetry dataset contains synthethic event logs that spans over multiple product types. Each row corresponds to a single telemetry event, which mimics real deployment scenarios originate from devices. Here are the following attributes: \\

% \begin{table}[h!]
% \centering
% \begin{tabular}{l p{10cm}}
% \toprule
% \textbf{Attribute} & \textbf{Description} \\
% \midrule
% Product Type & A categorical variable that indicates the type of product. Categories include \textbf{A}, \textbf{B}, \textbf{C}, \textbf{D}, \textbf{E}, \textbf{F}, and \textbf{Others} \\ 
% Event Type & Specifies the type of system or user-triggered event. Values include \textbf{open}, \textbf{close}, \textbf{save}, \textbf{reset}, and \textbf{error} \\
% Time of Event & Timestamp recording when each event occurred. All events fall within the period \textbf{May 1, 2024, to July 31, 2024} \\
% User ID & Anonymized identifier representing the user associated with event. \\
% \bottomrule
% \end{tabular}
% \caption{Data Attributes}
% \end{table}

% For DP-SGD, we employ PyTorch with the Opacus library to implement gradient clipping and Gaussian noise injection. For PE, we use the Stable Diffusion API (via Hugging Face \texttt{diffusers}) and compute DP nearest-neighbor histograms on CLIP embeddings.  
% Evaluation metrics include Fréchet Inception Distance (FID) and downstream classification accuracy of models trained on synthetic data.

%\subsection{Next steps}
%In Quarter 2, we will extend our evaluation to structured telemetry data from Intel, comprising system-level performance and usage metrics representative of real-world industrial pipelines. Applying DP-SGD and PE to this tabular and time-series data will reveal whether the privacy-utility trade-offs observed in image domains generalize to non-vision modalities.


% [Jason] Don't fiddle with anything under here!
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////
% ////////////////////////////////////////////////////////////////////////////////////////

% \section{Methods}

% \section{Results}

% \section{Discussion}

% \section{Conclusion}

% \section{\LaTeX{} Typesetting Examples}

% {\color{blue} This is not a real section; it's just here to show examples of how to format various components. Remove it before submitting!}

% \subsection{\LaTeX{} Basics}

% Here's \textbf{bold} and \textit{italicized} text. Here's \texttt{text\_that\_looks.like(code)}.

% \begin{itemize}
%     \item Here's a regular bulleted list item.
%     \item And another.
% \end{itemize}

% Here's a \href{https://datascience.ucsd.edu}{hyperlink}. If you want to use a numbered list, you can experiment with:

% \begin{enumerate}
%     \item This.
%     \item This.
%     \item And this.
% \end{enumerate}

% Here's how you might include a snippet of actual code:

% \begin{verbatim}
% # If you want to use syntax highlighting, look into the minted package.
% def f(x):
%     return 2 * x + 3
% \end{verbatim}

% Here's how you might format a single equation:

% $$\int_{-\infty}^\infty f_X(x)dx = 1$$

% And a chain of equations:

% \begin{align*}
%     \frac{1}{n}\sum_{i = 1}^n (x_i - \bar{x})^2 &= \frac{1}{n}\sum_{i = 1}^n (x_i^2 - 2x_i\bar{x} + \bar{x}^2)
%     \\ &= \frac{1}{n}\sum_{i = 1}^n x_i^2 - \frac{2}{n}\bar{x}\sum_{i = 1}^n x_i + \frac{\bar{x}^2}{n}\sum_{i = 1}^n 1
%     \\ &= \frac{1}{n}\sum_{i = 1}^n x_i^2 - 2\bar{x}^2 + \bar{x}^2
%     \\ &= \frac{1}{n}\sum_{i = 1}^n x_i^2 - \bar{x}^2
% \end{align*}


% \subsection{Figure Examples}

% Here are some example figures. 
% Figure \ref{fig:somefig1} presents a scatter plot.

% \begin{figure}[htbp]
% \centering
% \includegraphics[width=.65\linewidth]{figure/somefig1.pdf}
% \caption{Yes, put a few words or sentences here explaining what is in the figure.}
% \label{fig:somefig1}
% \end{figure}

% Figure \ref{fig:someotherfigs} presents some summaries of the performance of our model.
% The left panel of Figure \ref{fig:someotherfigs} presents something.
% The right panel of Figure \ref{fig:someotherfigs} presents some other things.

% \begin{figure}[htbp]
% \begin{minipage}{0.53\linewidth}
%   \centering
%   \includegraphics[width=\linewidth]{figure/somefig2.png}
% \end{minipage}
% \begin{minipage}{0.42\linewidth}
%   \centering
%   \includegraphics[width=\linewidth]{figure/somefig3.png}
% \end{minipage}
% \caption{You can put figures side-by-side as well.}
% \label{fig:someotherfigs}
% \end{figure}


% \subsection{Table Examples}

% Table \ref{tab:sometab1} presents some summary of the data.

% \begin{table}[htbp]
% \caption{Some Table Caption}
% \label{tab:sometab1}
% \resizebox{0.4\linewidth}{!}{\input{table/sometab1}}
% \end{table}

% Table \ref{tab:sometab2} presents some summaries of the performance of our model.

% \begin{table}[htbp]
% \caption{Some Other Table Caption}
% \label{tab:sometab2}
% \resizebox{0.9\linewidth}{!}{\input{table/sometab2}}
% \end{table}

% \subsection{Equations and Algorithms Examples}

% Algorithm \ref{alg:fuzzyKmeans} implements Fuzzy K-means.

% \begin{algorithm}
% \caption{Fuzzy K-means clustering algorithm}
% \label{alg:fuzzyKmeans}
% \begin{enumerate}
%     \item Choose primary centroids $v_{k}$
%     \item Compute the membership degree of all feature vectors in all clusters
%     \begin{equation}
%     u_{ki}  = \frac{1}{ \sum_{j=1}^K ( \frac{D^{2}(x_{i} - v_{k})}{D^{2}(x_{i} - v_{j})})^\frac{2} 
%     {m-1}}
%     \label{eq:kmeans}
%     \end{equation}
% \end{enumerate}
% \end{algorithm}

% Algorithm \ref{alg:net} calculates net activation.


% \begin{algorithm}
% \caption{Computing Net Activation}
% \label{alg:net}
% % \DontPrintSemicolon
% % \LinesNumbered
% \KwIn{$x_1, \ldots, x_n, w_1, \ldots, w_n$}
% \KwOut{$y$, the net activation}
% $y\leftarrow 0$\;
% \For{$i\leftarrow 1$ \KwTo $n$}{
% $y \leftarrow y + w_i*x_i$\;
% }
% \end{algorithm}

% In Variational Autoencoder (VAE), we directly maximize the Evidence Lower Bound (ELBO) using the following Equations \ref{eq:bla}--\ref{eq:blablabla}.
% \begin{align}
%   \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{z}\mid\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{z})}{q_{\boldsymbol{\phi}}(\boldsymbol{z}\mid\boldsymbol{x})}\right]
%   &= \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{z}\mid\boldsymbol{x})}\left[\log\frac{p_{\boldsymbol{\theta}}(\boldsymbol{x}\mid\boldsymbol{z})p(\boldsymbol{z})}{q_{\boldsymbol{\phi}}(\boldsymbol{z}\mid\boldsymbol{x})}\right] \label{eq:bla} \\
%   &= \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{z}\mid\boldsymbol{x})}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}\mid\boldsymbol{z})\right] + \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{z}\mid\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{z})}{q_{\boldsymbol{\phi}}(\boldsymbol{z}\mid\boldsymbol{x})}\right] \label{eq:blabla} \\
%   &= \underbrace{\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{z}\mid\boldsymbol{x})}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}\mid\boldsymbol{z})\right]}_\text{reconstruction term} - \underbrace{\mathcal{D}_{\text{KL}}(q_{\boldsymbol{\phi}}(\boldsymbol{z}\mid\boldsymbol{x}) \mid\mid p(\boldsymbol{z}))}_\text{prior matching term} \label{eq:blablabla}
% \end{align}

% \subsection{Inline Citation Examples}

% Citation in text (no parentheses): use \texttt{{\textbackslash}cite\{citekey\}}. 
% For example, \cite{breiman2011}, \cite{devlin2019bert}.

% Citation in parentheses: use \texttt{{\textbackslash}citep\{citekey\}}. 
% For example: \citep{vaswani2023attention}, \citep{karras2019stylebased}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Reference / Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\makereference

\nocite{*}
\bibliography{reference}
\bibliographystyle{style/dsc180bibstyle}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% Appendix
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \clearpage
% \makeappendix

% \subsection{Training Details}

% \subsection{Additional Figures}

% \subsection{Additional Tables}


\end{document}